{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/kennethenevoldsen/asent\"><img src=\"https://github.com/KennethEnevoldsen/asent/blob/main/docs/img/logo_black_font.png?raw=true\" width=\"300\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "Before we start we should install asent this can be done simply by commenting the following lines out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install asent\n",
    "#!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "> *Note*: This tutorial is English but the library also allows for multiple other languages to see all languages available check out the [Languages section](https://kennethenevoldsen.github.io/asent/languages/index.html) on the website.\n",
    "\n",
    "Asent is a package for fast and transparent sentiment analysis. The package applied uses a dictionary of words rated as either positive or negative and a series of rules to determine whether a word, sentence or a document is positive or negative. The current rules account for negations (i.e. \"not happy\"), intensifiers (\"very happy\") and account for contrastive conjugations (i.e. \"but\") as well as other emphasis markers such as exclamation marks, casing and question marks. The following will take you through how the sentiment is calculated in a step by step fashion.\n",
    "\n",
    "To start of with we will need a spaCy pipeline as well as we will need to add the asent pipeline `asent_en_v1` to it, where `en` indicate that it is the English pipeline and that `v1` indicate that it is version 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<asent.component.Asent at 0x11282f9d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asent\n",
    "import spacy\n",
    "\n",
    "# load spacy pipeline\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# add the rule-based sentiment model\n",
    "nlp.add_pipe(\"asent_en_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see all the available components you can simply run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asent_da_v1\n",
      "asent_en_v1\n",
      "asent_no_v1\n",
      "asent_sv_v1\n"
     ]
    }
   ],
   "source": [
    "for c in asent.components.get_all():\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token valence and polarity\n",
    "As seen in figure 1. token valence is simply the value gained from a lookup in a rated dictionary. For instance if the have the example sentence \"I am not very happy\" the word \"happy\" have a positive human rating of 2.7 which is not amplified by the word being in all-caps.\n",
    "\n",
    "\n",
    "<h3 align=\"center\">\n",
    "<figure>\n",
    "<img src=\"https://raw.githubusercontent.com/KennethEnevoldsen/asent/main/docs/img/token_polarity.png\" width=\"700\" />\n",
    "</figure>\n",
    "  <small>\n",
    "  Figure 1: Calculation of token polarity and valence\n",
    "  </small>\n",
    "</h3>\n",
    "\n",
    "We can extract valence quite easily using the `valence` extension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t 0.0\n",
      "am \t 0.0\n",
      "not \t 0.0\n",
      "very \t 0.0\n",
      "happy \t 2.7\n",
      ". \t 0.0\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I am not very happy.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \"\\t\", token._.valence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, in this context happy should not be perceived positively as it is negated, thus we should look at token polarity. Token polarity examines if a word is negated and it so multiplies the values by a negative constant. This constant is emperically derived to be 0.74 [(Hutto and Gilbert, 2014)](https://ojs.aaai.org/index.php/ICWSM/article/view/14550). Similarly with the specific example we chose we can also see that \"happy\" is intensified by the word \"very\", while increases it polarity. The constant 0.293 is similarly, emperically derived by Hutto and Gilbert. We can similarly extract the polarity using the `polarity` extension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity=0.0 token=I span=I\n",
      "polarity=0.0 token=am span=am\n",
      "polarity=0.0 token=not span=not\n",
      "polarity=0.0 token=very span=very\n",
      "polarity=-2.215 token=happy span=not very happy\n",
      "polarity=0.0 token=. span=.\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token._.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that here we even get further information, that token \"happy\", has a polarity of -2.215 and that this includes the span (sequence of tokens) \"not very happy\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing polarity\n",
    "Asent also include a series of methods to visualize the token polarity:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I am \n",
       "<mark class=\"entity\" style=\"background: #fba15b; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    not very happy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">-2.2</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "asent.visualize(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document and Span Polarity\n",
    "\n",
    "We want to do more than simply calculate the polarity of the token, we want to extract information about the entire sentence (span) and aggregate this across the entire document.\n",
    "\n",
    "<h3 align=\"center\">\n",
    "<figure>\n",
    "<img src=\"https://raw.githubusercontent.com/KennethEnevoldsen/asent/main/docs/img/doc_polarity.png\" width=\"600\" />\n",
    "</figure>\n",
    "  <small>\n",
    "  Figure 2: Calculation of document polarity\n",
    "  </small>\n",
    "</h3>\n",
    "\n",
    "The calculation of the sentence polarity includes a couple of steps. \n",
    "First, it checks if the sentence contains a contrastive conjugation (e.g. \"but\"), then overweight things after the but and underweight previous elements. This seems quite natural for example the sentence \"The movie was great, but the acting was horrible\", noticeably put more weight on the second statement. This has also been shown empirically by [(Hutto and Gilbert, 2014)](https://ojs.aaai.org/index.php/ICWSM/article/view/14550). Afterwards, the model takes into account question marks and exclamations marks, which both increases the polarity of the sentence with negative sentences becoming more negative and positive sentences becoming less negative. Lastly, the polarity is normalized between approximately -1 and 1.\n",
    "\n",
    "You can easily extract the sentence polarity and the document polarity using: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg=0.391 neu=0.609 pos=0.0 compound=-0.4964 span=I am not very happy.\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    print(sentence._.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg=0.391 neu=0.609 pos=0.0 compound=-0.4964\n"
     ]
    }
   ],
   "source": [
    "# or for multiple sentences:\n",
    "print(doc._.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the normalized score for both the `compound`, or aggregated, polarity as well the the neutral `neu`, negative `neg`, and positive `pos`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bf26e8f1c179b01cb59a2d6823fb6cd29f134e7c953e081ed300474f231d990"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('asent': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
